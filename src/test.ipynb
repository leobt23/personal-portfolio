{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.4.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.10-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain)\n",
      "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from langchain) (2.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: anyio in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.24->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (4.12.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.12-cp312-none-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB ? eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leo_b\\anaconda3\\envs\\med_da\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.5/1.0 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 21.3 MB/s eta 0:00:00\n",
      "Downloading langchain_ollama-0.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading ollama-0.4.4-py3-none-any.whl (13 kB)\n",
      "Downloading aiohttp-3.11.10-cp312-cp312-win_amd64.whl (437 kB)\n",
      "   ---------------------------------------- 0.0/437.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 437.4/437.4 kB 26.7 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB ? eta 0:00:00\n",
      "Downloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
      "   ---------------------------------------- 0.0/410.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 410.6/410.6 kB 25.0 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.2.2-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 320.6/320.6 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.4/2.1 MB 12.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.1 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 22.1 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.0/63.0 kB ? eta 0:00:00\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.3/51.3 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 299.7/299.7 kB ? eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.12-cp312-none-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.2/135.2 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.1/44.1 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 90.4/90.4 kB ? eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, multidict, jsonpointer, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, jsonpatch, httpx, aiosignal, ollama, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain-ollama, langchain\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 attrs-24.2.0 frozenlist-1.5.0 greenlet-3.1.1 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.11 langchain-core-0.3.24 langchain-ollama-0.2.1 langchain-text-splitters-0.3.2 langsmith-0.2.2 multidict-6.1.0 ollama-0.4.4 orjson-3.10.12 propcache-0.2.1 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-ollama ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not a big drinker, but if I had to choose, I'd say my favorite wine is probably a Pinot Grigio. There's something about its crisp, citrusy flavor that just refreshes me after a long day!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Ansewr the question below:\n",
    "\n",
    "Here is the conversation history: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | model\n",
    "\n",
    "result = chain.invoke({\"context\":\"\", \"question\": \"What is your favorite wine?\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Med_DA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
